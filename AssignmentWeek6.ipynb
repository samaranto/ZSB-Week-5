{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment  Practice Text classification with Naive Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook made by   (If not filled in correctly: 0 pts for assignment)\n",
    "\n",
    "__Name(s)__: \n",
    "\n",
    "__Student id(s)__ : \n",
    "\n",
    "### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here). The link must be to some place on the web, not to a local file. **Assignments without the selfies will not be graded and receive 0 points.**\n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img src='link to your selfie'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice Text classification with Naive Bayes  \n",
    "        \n",
    "        \n",
    "        \n",
    "<h3>Abstract</h3>\n",
    "<p>We will do text classification on a collection of Dutch parliamentary questions.\n",
    "    The website <a href=\"https://zoek.officielebekendmakingen.nl/zoeken/parlementaire_documenten\">officielebekendmakingen.nl</a>lets you search in \"kamervragen\".\n",
    "    You can donwload\n",
    "    <a href='http://data.politicalmashup.nl/kamervragen/PoliDocs_Kamervragen.zip'>this zipfile with Kamervragen in XML</a>\n",
    "    to see some of the  data in XML format. \n",
    "    It also contains style sheets to show the XML well in a browser.  \n",
    "    The <a href='http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/'>MYSQL directory</a> contains an <a href='http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/KVR14807.xml'>example   Kamervraag XML file</a> and a file `kvr.csv.gz` with all those kamervragen in a handy csv format. Note that in your browser you see the result of applying stylesheets. So choose View Source or open it in an editor.</p>\n",
    "\n",
    "<h3>First exploration</h3>\n",
    "\n",
    "See below.\n",
    "\n",
    "<h2>Exercise</h2>\n",
    "\n",
    "<p>We will use the fields in elements of the form <tt> &lt;item attribuut=\"Afkomstig_van\"></tt> as our classes. \n",
    "    These are the ministeries to whom the question is addressed.\n",
    "    An example is \n",
    "    <pre>\n",
    "        &lt;item attribuut=\"Afkomstig_van\">Landbouw, Natuurbeheer en Visserij (LNV)&lt;/item>\n",
    "    </pre>\n",
    "    Note that these labels are <strong>not normalized</strong>, see e.g. the counts below:\n",
    "    <pre>\n",
    "Justitie (JUS)                                                   3219\n",
    "Volksgezondheid, Welzijn en Sport (VWS)                          2630\n",
    "Buitenlandse Zaken (BUZA)                                        1796\n",
    "Verkeer en Waterstaat (VW)                                       1441\n",
    "Justitie                                                         1333\n",
    "Sociale Zaken en Werkgelegenheid (SZW)                           1231\n",
    "Onderwijs, Cultuur en Wetenschappen (OCW)                        1187\n",
    "Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer (VROM)     984\n",
    "FinanciÃ«n (FIN)                                                   960\n",
    "Volksgezondheid, Welzijn en Sport                                 951\n",
    "Economische Zaken (EZ)                                            946\n",
    "Buitenlandse Zaken                                                753\n",
    "Binnenlandse Zaken en Koninkrijksrelaties (BZK)                   725\n",
    "Verkeer en Waterstaat                                             724\n",
    "Defensie (DEF)                                                    646\n",
    "Sociale Zaken en Werkgelegenheid                                  607\n",
    "Landbouw, Natuurbeheer en Visserij (LNV)                          586\n",
    "Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer            554\n",
    "Onderwijs, Cultuur en Wetenschappen                               532\n",
    "Vreemdelingenzaken en Integratie (VI)                             466\n",
    "    </pre>\n",
    "</p>\n",
    "\n",
    "  <ol>\n",
    "      <li>Normalize the values for \"ministerie\" and choose 10 ministeries to work with. </li>\n",
    "      <li>Implement the two algorithms in Fig MRS.13.2, using your earlier code for creating term and document frequencies.\n",
    "      It might be easier to use the representation and formula given in MRS section 13.4.1.</li>\n",
    "      <li>On this collection, train NB text classifiers for 10 different classes with enough and interesting data.</li>\n",
    "      <li>Compute for each term and each of your 10 classes its utility for that class using mutual information.</li>\n",
    "      <li>For each class, show the top 10 words as in Figure 13.7 in MRS.</li>\n",
    "      <li>Evaluate your classifiers using Precision, Recall and F1. (\n",
    "           <br/>\n",
    "          Give a table in which you show these values for using the top 10, top 100 terms and all terms, for all of your 10 classes.\n",
    "          Thus do feature selection per class, and use for each class the top n best features for that class. \n",
    "          <br/>\n",
    "      Also show the microaverage(s) for all 10 classes together.\n",
    "      <br/>\n",
    "      If you like you can also present this in a figure like MRS.13.8. \n",
    "      Then compute the F1 measure for the same number of terms as in that figure.</li>\n",
    "      <li>Reflect and report briefly about your choices in this process and about the obtained results. </li>\n",
    "  </ol>\n",
    "\n",
    "<h3>Training/Testing</h3>\n",
    "<p>It is important that you do not test your classifier using documents that have also been used in training.\n",
    "    So split up your collection in a training set and a test set. A 80%-20% split is reasonable.\n",
    "\n",
    "<br/>\n",
    "    If you have too little data you can use 5 or <a href=\"http://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation\">10-fold cross validation</a>.</p>\n",
    "\n",
    "<h2>Form of presentation</h2>\n",
    "<ul>\n",
    "    <li>Make slides or wikipages and have your system running (this could just be an IPython notebook with a classify function that accepts any string and classifies it.) ~~and be able to accept documents from the web.~~ </li>\n",
    "    <li>Create one or two slides or wikipages for each of the sub exercises listed above.\n",
    "</li>\n",
    "<li>Make it clear in the heading of the slides which sub exercises you talk about.</li>\n",
    "    <li>Show running code with one or two  good examples (a TP of course, but also a FP and an error-analysis is nice to show). </li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "<h2>Form of handing in your final product</h2>\n",
    "<ul>\n",
    "    <li>An IPython notebook would be perfect, with clear indications which part of the code answers which subquestion.</li>\n",
    "    <li>A clear git repo, with good comments and a clear separation and indication what code does what is also fine.</li>\n",
    "    <li> You are free to program in whatever language you prefer.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40516, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jaar</th>\n",
       "      <th>partij</th>\n",
       "      <th>titel</th>\n",
       "      <th>vraag</th>\n",
       "      <th>antwoord</th>\n",
       "      <th>ministerie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KVR1000.xml</th>\n",
       "      <td>1994</td>\n",
       "      <td>PvdA</td>\n",
       "      <td>De vragen betreffen de betrouwbaarheid van de...</td>\n",
       "      <td>Hebt u kennisgenomen van het televisieprogram...</td>\n",
       "      <td>Ja. Het bedoelde geluidmeetpunt is eigendom v...</td>\n",
       "      <td>Verkeer en Waterstaat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10000.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>PvdA</td>\n",
       "      <td>Vragen naar aanleiding van berichten (uitzend...</td>\n",
       "      <td>Kent u de berichten over de situatie in de Me...</td>\n",
       "      <td></td>\n",
       "      <td>Justitie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10001.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>SP</td>\n",
       "      <td>Vragen naar aanleiding van de berichten \"Nede...</td>\n",
       "      <td>Kent u de berichten «Nederland steunt de Soeh...</td>\n",
       "      <td></td>\n",
       "      <td>Financien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10002.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>PvdA</td>\n",
       "      <td>Vragen over de gebrekkige opvang van verpleeg...</td>\n",
       "      <td>Kent u het bericht over onderzoek van Nu91 me...</td>\n",
       "      <td>Ja. Het onderzoek van NU’91 wijst uit dat het...</td>\n",
       "      <td>Volksgezondheid, Welzijn en Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10003.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>PvdA</td>\n",
       "      <td>Vragen over onbetrouwbaarheid van filemeldingen.</td>\n",
       "      <td>Hebt u kennisgenomen van de berichten over de...</td>\n",
       "      <td>Ja. Nee. Door de waarnemers van het Algemeen ...</td>\n",
       "      <td>Verkeer en Waterstaat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10004.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>D66</td>\n",
       "      <td>Vragen naar aanleiding van het bericht in de ...</td>\n",
       "      <td>Kent u het bericht als zou het RIVM onjuiste ...</td>\n",
       "      <td>Ja. Nee. Als reactie op het Volkskrant-artike...</td>\n",
       "      <td>Verkeer en Waterstaat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10006.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>PvdA</td>\n",
       "      <td></td>\n",
       "      <td>Kent u berichten over asbestgevaar voor KFOR-...</td>\n",
       "      <td>Kamerstuk 22 181, nr. 293</td>\n",
       "      <td>Defensie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10007.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>D66</td>\n",
       "      <td>Vragen naar aanleiding van het artikel ''Eila...</td>\n",
       "      <td>Kent u het artikel Eilander artsen vechten vo...</td>\n",
       "      <td>Ja. Ik ben van mening, en ga er vanuit dat di...</td>\n",
       "      <td>Volksgezondheid, Welzijn en Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10008.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>GroenLinks</td>\n",
       "      <td>Vragen over de mogelijke terugkeer naar het o...</td>\n",
       "      <td>Kent u het artikel «De specialist declareert ...</td>\n",
       "      <td>Ja. Neen, op dit moment is in drie van de rui...</td>\n",
       "      <td>Volksgezondheid, Welzijn en Sport (VWS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10009.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>SP</td>\n",
       "      <td>Vragen over de uiteindelijke invulling van ui...</td>\n",
       "      <td>Is over de uiteindelijke invulling van de uit...</td>\n",
       "      <td>De Ziekenfondsraad, thans College voor zorgve...</td>\n",
       "      <td>Volksgezondheid, Welzijn en Sport (VWS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR1001.xml</th>\n",
       "      <td>1994</td>\n",
       "      <td>GroenLinks</td>\n",
       "      <td>De vragen betreffen subsidiëring van (een haa...</td>\n",
       "      <td>Wilt u de pre´-haalbaarheidsstudie naar de mo...</td>\n",
       "      <td>Het rapport van deze studie is nog niet geree...</td>\n",
       "      <td>Landbouw, Natuurbeheer en Visserij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10010.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>CDA</td>\n",
       "      <td>Aanvullende vragen op die gesteld door het li...</td>\n",
       "      <td>Heeft u in een brief aan artsen, apothekers e...</td>\n",
       "      <td>Ja, het betreft zelfzorggeneesmiddelen die in...</td>\n",
       "      <td>Volksgezondheid, Welzijn en Sport (VWS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10011.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>SGP</td>\n",
       "      <td>Vragen over de introductie van de zogenaamde ...</td>\n",
       "      <td>Kent u de berichtgeving rond de introductie v...</td>\n",
       "      <td>Ja. Het geneesmiddel Mifegyne betreft een gen...</td>\n",
       "      <td>Volksgezondheid, Welzijn en Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10013.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>GroenLinks</td>\n",
       "      <td>Vragen naar aanleiding van het artikel \"Een h...</td>\n",
       "      <td>Bent u op de hoogte van de huidige situatie i...</td>\n",
       "      <td>Ja. Vele sectoren in de Surinaamse samenlevin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10014.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>PvdA</td>\n",
       "      <td>Vragen over het feit dat de Roma-zigeuners he...</td>\n",
       "      <td>Heeft u kennisgenomen van de door het Europea...</td>\n",
       "      <td>Ja. Deze berichten zijn zorgwekkend. Zij corr...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10016.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>CDA</td>\n",
       "      <td>Vragen over het verbod van de Europese Commis...</td>\n",
       "      <td>Heeft de Europese Commissie de door de regeri...</td>\n",
       "      <td>Deels. De Europese Commissie heeft een gedeel...</td>\n",
       "      <td>Financien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10017.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>SP</td>\n",
       "      <td>Vragen naar aanleiding van een geval van hulp...</td>\n",
       "      <td>Hebt u kennisgenomen van de verslaglegging in...</td>\n",
       "      <td>Ja. Het betrof een geval van hulp bij zelfdod...</td>\n",
       "      <td>Justitie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10018.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>CDA</td>\n",
       "      <td>Vragen over de bestemming van grond die bij h...</td>\n",
       "      <td>Komt bij het boren van tunnels grond vrij die...</td>\n",
       "      <td>Er komt inderdaad grond vrij dat vermengd wor...</td>\n",
       "      <td>Verkeer en Waterstaat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR10019.xml</th>\n",
       "      <td>1999</td>\n",
       "      <td>CDA</td>\n",
       "      <td></td>\n",
       "      <td>Hoe luidt exact de uitspraak van de WTO inzak...</td>\n",
       "      <td></td>\n",
       "      <td>Landbouw, Natuurbeheer en Visserij</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KVR1002.xml</th>\n",
       "      <td>1994</td>\n",
       "      <td>GPV</td>\n",
       "      <td>De vragen betreffen een voorgenomen voorstel ...</td>\n",
       "      <td>Heeft de Franse minister van Buitenlandse Zak...</td>\n",
       "      <td>Ja. Frankrijk is voornemens dit voorstel tijd...</td>\n",
       "      <td>Buitenlandse Zaken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                jaar       partij  \\\n",
       "KVR1000.xml     1994         PvdA   \n",
       " KVR10000.xml   1999         PvdA   \n",
       " KVR10001.xml   1999           SP   \n",
       " KVR10002.xml   1999         PvdA   \n",
       " KVR10003.xml   1999         PvdA   \n",
       " KVR10004.xml   1999          D66   \n",
       " KVR10006.xml   1999         PvdA   \n",
       " KVR10007.xml   1999          D66   \n",
       " KVR10008.xml   1999   GroenLinks   \n",
       " KVR10009.xml   1999           SP   \n",
       " KVR1001.xml    1994   GroenLinks   \n",
       " KVR10010.xml   1999          CDA   \n",
       " KVR10011.xml   1999          SGP   \n",
       " KVR10013.xml   1999   GroenLinks   \n",
       " KVR10014.xml   1999         PvdA   \n",
       " KVR10016.xml   1999          CDA   \n",
       " KVR10017.xml   1999           SP   \n",
       " KVR10018.xml   1999          CDA   \n",
       " KVR10019.xml   1999          CDA   \n",
       " KVR1002.xml    1994          GPV   \n",
       "\n",
       "                                                           titel  \\\n",
       "KVR1000.xml     De vragen betreffen de betrouwbaarheid van de...   \n",
       " KVR10000.xml   Vragen naar aanleiding van berichten (uitzend...   \n",
       " KVR10001.xml   Vragen naar aanleiding van de berichten \"Nede...   \n",
       " KVR10002.xml   Vragen over de gebrekkige opvang van verpleeg...   \n",
       " KVR10003.xml   Vragen over onbetrouwbaarheid van filemeldingen.   \n",
       " KVR10004.xml   Vragen naar aanleiding van het bericht in de ...   \n",
       " KVR10006.xml                                                      \n",
       " KVR10007.xml   Vragen naar aanleiding van het artikel ''Eila...   \n",
       " KVR10008.xml   Vragen over de mogelijke terugkeer naar het o...   \n",
       " KVR10009.xml   Vragen over de uiteindelijke invulling van ui...   \n",
       " KVR1001.xml    De vragen betreffen subsidiëring van (een haa...   \n",
       " KVR10010.xml   Aanvullende vragen op die gesteld door het li...   \n",
       " KVR10011.xml   Vragen over de introductie van de zogenaamde ...   \n",
       " KVR10013.xml   Vragen naar aanleiding van het artikel \"Een h...   \n",
       " KVR10014.xml   Vragen over het feit dat de Roma-zigeuners he...   \n",
       " KVR10016.xml   Vragen over het verbod van de Europese Commis...   \n",
       " KVR10017.xml   Vragen naar aanleiding van een geval van hulp...   \n",
       " KVR10018.xml   Vragen over de bestemming van grond die bij h...   \n",
       " KVR10019.xml                                                      \n",
       " KVR1002.xml    De vragen betreffen een voorgenomen voorstel ...   \n",
       "\n",
       "                                                           vraag  \\\n",
       "KVR1000.xml     Hebt u kennisgenomen van het televisieprogram...   \n",
       " KVR10000.xml   Kent u de berichten over de situatie in de Me...   \n",
       " KVR10001.xml   Kent u de berichten «Nederland steunt de Soeh...   \n",
       " KVR10002.xml   Kent u het bericht over onderzoek van Nu91 me...   \n",
       " KVR10003.xml   Hebt u kennisgenomen van de berichten over de...   \n",
       " KVR10004.xml   Kent u het bericht als zou het RIVM onjuiste ...   \n",
       " KVR10006.xml   Kent u berichten over asbestgevaar voor KFOR-...   \n",
       " KVR10007.xml   Kent u het artikel Eilander artsen vechten vo...   \n",
       " KVR10008.xml   Kent u het artikel «De specialist declareert ...   \n",
       " KVR10009.xml   Is over de uiteindelijke invulling van de uit...   \n",
       " KVR1001.xml    Wilt u de pre´-haalbaarheidsstudie naar de mo...   \n",
       " KVR10010.xml   Heeft u in een brief aan artsen, apothekers e...   \n",
       " KVR10011.xml   Kent u de berichtgeving rond de introductie v...   \n",
       " KVR10013.xml   Bent u op de hoogte van de huidige situatie i...   \n",
       " KVR10014.xml   Heeft u kennisgenomen van de door het Europea...   \n",
       " KVR10016.xml   Heeft de Europese Commissie de door de regeri...   \n",
       " KVR10017.xml   Hebt u kennisgenomen van de verslaglegging in...   \n",
       " KVR10018.xml   Komt bij het boren van tunnels grond vrij die...   \n",
       " KVR10019.xml   Hoe luidt exact de uitspraak van de WTO inzak...   \n",
       " KVR1002.xml    Heeft de Franse minister van Buitenlandse Zak...   \n",
       "\n",
       "                                                        antwoord  \\\n",
       "KVR1000.xml     Ja. Het bedoelde geluidmeetpunt is eigendom v...   \n",
       " KVR10000.xml                                                      \n",
       " KVR10001.xml                                                      \n",
       " KVR10002.xml   Ja. Het onderzoek van NU’91 wijst uit dat het...   \n",
       " KVR10003.xml   Ja. Nee. Door de waarnemers van het Algemeen ...   \n",
       " KVR10004.xml   Ja. Nee. Als reactie op het Volkskrant-artike...   \n",
       " KVR10006.xml                          Kamerstuk 22 181, nr. 293   \n",
       " KVR10007.xml   Ja. Ik ben van mening, en ga er vanuit dat di...   \n",
       " KVR10008.xml   Ja. Neen, op dit moment is in drie van de rui...   \n",
       " KVR10009.xml   De Ziekenfondsraad, thans College voor zorgve...   \n",
       " KVR1001.xml    Het rapport van deze studie is nog niet geree...   \n",
       " KVR10010.xml   Ja, het betreft zelfzorggeneesmiddelen die in...   \n",
       " KVR10011.xml   Ja. Het geneesmiddel Mifegyne betreft een gen...   \n",
       " KVR10013.xml   Ja. Vele sectoren in de Surinaamse samenlevin...   \n",
       " KVR10014.xml   Ja. Deze berichten zijn zorgwekkend. Zij corr...   \n",
       " KVR10016.xml   Deels. De Europese Commissie heeft een gedeel...   \n",
       " KVR10017.xml   Ja. Het betrof een geval van hulp bij zelfdod...   \n",
       " KVR10018.xml   Er komt inderdaad grond vrij dat vermengd wor...   \n",
       " KVR10019.xml                                                      \n",
       " KVR1002.xml    Ja. Frankrijk is voornemens dit voorstel tijd...   \n",
       "\n",
       "                                             ministerie  \n",
       "KVR1000.xml                       Verkeer en Waterstaat  \n",
       " KVR10000.xml                                  Justitie  \n",
       " KVR10001.xml                                 Financien  \n",
       " KVR10002.xml         Volksgezondheid, Welzijn en Sport  \n",
       " KVR10003.xml                     Verkeer en Waterstaat  \n",
       " KVR10004.xml                     Verkeer en Waterstaat  \n",
       " KVR10006.xml                                  Defensie  \n",
       " KVR10007.xml         Volksgezondheid, Welzijn en Sport  \n",
       " KVR10008.xml   Volksgezondheid, Welzijn en Sport (VWS)  \n",
       " KVR10009.xml   Volksgezondheid, Welzijn en Sport (VWS)  \n",
       " KVR1001.xml         Landbouw, Natuurbeheer en Visserij  \n",
       " KVR10010.xml   Volksgezondheid, Welzijn en Sport (VWS)  \n",
       " KVR10011.xml         Volksgezondheid, Welzijn en Sport  \n",
       " KVR10013.xml                                       NaN  \n",
       " KVR10014.xml                                       NaN  \n",
       " KVR10016.xml                                 Financien  \n",
       " KVR10017.xml                                  Justitie  \n",
       " KVR10018.xml                     Verkeer en Waterstaat  \n",
       " KVR10019.xml        Landbouw, Natuurbeheer en Visserij  \n",
       " KVR1002.xml                         Buitenlandse Zaken  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change to KVR1000.csv.gz if this becomes to0 slow for you\n",
    "kvrdf= pd.read_csv('http://maartenmarx.nl/teaching/zoekmachines/LectureNotes/MySQL/KVR.csv.gz', \n",
    "                   compression='gzip', sep='\\t', encoding='utf-8',\n",
    "                   index_col=0, names=['jaar', 'partij','titel','vraag','antwoord','ministerie']) \n",
    "print kvrdf.shape\n",
    "kvrdf.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Justitie (JUS)                                                   3219\n",
       " Volksgezondheid, Welzijn en Sport (VWS)                          2630\n",
       " Buitenlandse Zaken (BUZA)                                        1796\n",
       " Verkeer en Waterstaat (VW)                                       1441\n",
       " Justitie                                                         1333\n",
       " Sociale Zaken en Werkgelegenheid (SZW)                           1231\n",
       " Onderwijs, Cultuur en Wetenschappen (OCW)                        1187\n",
       " Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer (VROM)     984\n",
       " Financiën (FIN)                                                   960\n",
       " Volksgezondheid, Welzijn en Sport                                 951\n",
       " Economische Zaken (EZ)                                            946\n",
       " Buitenlandse Zaken                                                753\n",
       " Binnenlandse Zaken en Koninkrijksrelaties (BZK)                   725\n",
       " Verkeer en Waterstaat                                             724\n",
       " Defensie (DEF)                                                    646\n",
       " Sociale Zaken en Werkgelegenheid                                  607\n",
       " Landbouw, Natuurbeheer en Visserij (LNV)                          586\n",
       " Volkshuisvesting, Ruimtelijke Ordening en Milieubeheer            554\n",
       " Onderwijs, Cultuur en Wetenschappen                               532\n",
       " Vreemdelingenzaken en Integratie (VI)                             466\n",
       "Name: ministerie, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 428 minesteries\n",
    "# 27189 keer toegewezen\n",
    "\n",
    "kvrdf.ministerie.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter,defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import glob\n",
    "import nltk\n",
    "import math\n",
    "from __future__ import division\n",
    "import operator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "allvragen = []\n",
    "for titel in kvrdf.titel:\n",
    "    if titel != 'nan':\n",
    "        allvragen.append(titel)\n",
    "print type(allvragen)\n",
    "tokenized_sents = [word_tokenize(i) for i in allvragen[23466]]\n",
    "print len(tokenized_sents)\n",
    "# Join all titels of the questions together\n",
    "#allvragen= '\\n'.join(list(kvrdf.titel))\n",
    "#print len(allvragen), allvragen[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f068ba569817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;31m# Tokenize and turn into a bag of words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mBoW\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallvragen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;31m# show the top 20 most used words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mBoW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\__init__.pyc\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     return [token for sent in sent_tokenize(text, language)\n\u001b[0m\u001b[1;32m    107\u001b[0m             for token in _treebank_word_tokenize(sent)]\n\u001b[1;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\__init__.pyc\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \"\"\"\n\u001b[1;32m     90\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[1;31m# Standard word tokenizer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \"\"\"\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \"\"\"\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \"\"\"\n\u001b[1;32m   1303\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         \u001b[1;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m             \u001b[0msl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \"\"\"\n\u001b[1;32m    309\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_tok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or buffer"
     ]
    }
   ],
   "source": [
    "# Tokenize and turn into a bag of words\n",
    "BoW= Counter(nltk.word_tokenize(allvragen))\n",
    "# show the top 20 most used words \n",
    "BoW.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-1ccfa131c2a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDutchStop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mBoW\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mBoW\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mallvragen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDutchStop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[1;31m# show the top 20 most used words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mBoW\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\__init__.pyc\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     return [token for sent in sent_tokenize(text, language)\n\u001b[0m\u001b[1;32m    107\u001b[0m             for token in _treebank_word_tokenize(sent)]\n\u001b[1;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\__init__.pyc\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \"\"\"\n\u001b[1;32m     90\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[1;31m# Standard word tokenizer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \"\"\"\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdebug_decisions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36msentences_from_text\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1272\u001b[0m         \u001b[0mfollows\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mperiod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \"\"\"\n\u001b[0;32m-> 1274\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspan_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36mspan_tokenize\u001b[0;34m(self, text, realign_boundaries)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_realign_boundaries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mslices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msentences_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealign_boundaries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36m_realign_boundaries\u001b[0;34m(self, text, slices)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \"\"\"\n\u001b[1;32m   1303\u001b[0m         \u001b[0mrealign\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         \u001b[1;32mfor\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_pair_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m             \u001b[0msl1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrealign\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msl1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msl2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36m_pair_iter\u001b[0;34m(it)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \"\"\"\n\u001b[1;32m    309\u001b[0m     \u001b[0mit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mprev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\Samar\\Anaconda2\\lib\\site-packages\\nltk\\tokenize\\punkt.pyc\u001b[0m in \u001b[0;36m_slices_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_slices_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m         \u001b[0mlast_break\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[1;32mfor\u001b[0m \u001b[0mmatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lang_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod_context_re\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinditer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m             \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'after_tok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_contains_sentbreak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or buffer"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "DutchStop= stopwords.words('dutch')\n",
    "print len(DutchStop)\n",
    "\n",
    "BoW= BoW= Counter([w for w in nltk.word_tokenize(allvragen) if not w in set(DutchStop)])\n",
    "# show the top 20 most used words \n",
    "BoW.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Samar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
